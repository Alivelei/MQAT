lang_choice = "en"
run_mode = "train"


[dataset]
dataset_path = "./CLEFdata/train/Train_images/"
dataset_json_path = "./CLEFdata/train/train.json"
dataset_img_path = "./CLEFdata/train/Train_images"


[model]
learning_rate = 0.005
qus_embedding_dim = 300
dropout = 0.2
num_heads = 8
random_seed = 1024
in_channels = 3
seq_len = 49
emb_size = 768
img_size = 224
depth = 12
ngf_conv = 64
start_epoch_save = 1500
save_frequency = 50


[config]
batch_size = 2
shuffle = true
epochs = 20000
device_ids = [0]
log_path = "./log"
glove_path = "./model/glove_emb_300d.npy"
qus_ws_path = "./model/qus_ws.pkl"
ans_ws_path = "./model/ans_ws.pkl"
sort_ws_path = "./model/sort_ws.pkl"
qus_seq_len = 20
qus_word_size = 104
ans_word_size = 1549
answer_open = 0
answer_close = 1
sort_number = 11
num_workers = 0
train_epoch_effect_path = "./param/train_epoch_effect.json"
test_epoch_effect_path = "./param/test_epoch_effect.json"
latest_model_path = "./model/latest_model.pth"
latest_parameter_path = "./model/latest_parameter.pth"
best_model_path = "./model/best_model.pth"
best_parameter_path = "./model/best_parameter.pth"
test_best_model_path = "./model/test_best_model.pth"
test_best_parameter_path = "./model/test_best_parameter.pth"


[image]
img_height = 224
img_width = 224
img_rotation = 10
img_mean = [0.2634, 0.2634, 0.2634]
img_std = [0.2758, 0.2758, 0.2758]
resized_crop_left = 0.2
resized_crop_right = 1.0
blur = [0.1, 2.0]
b_size = [5, 5]
blur_p = 0.5
apply_p = 0.8
img_flip = 0.5
brightness = 0.4
contrast = 0.4
saturation = 0.4
hue = 0.4
grayscale = 0.2
mix_up_probability = 1



